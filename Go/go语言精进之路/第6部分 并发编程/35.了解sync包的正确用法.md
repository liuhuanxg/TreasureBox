# 第35 条 了解sync包的正确用法

`sync`标准库提供了针对传统**基于共享内存并发模型**的基本术语，包括互斥锁（sync.Mutex）、读写锁（sync.RWMutex）、条件变量（sync.Cond）等。

## 35.1 sync包还是channel

Go语言提倡"不要通过共享内存来通信，而应该通过通信来共享内存"。但是在一些场景中，依然需要sync包提供的低级同步原语：

1. **需要高性能的临界区同步机制场景**

   在go中，channel属于高级同步原语，实现是建构在低级同步原语之上。因此，channel自身的性能与低级同步原语相比要略微逊色。因此，如果在高性能的临界区同步机制情况下，sync包提供的低级同步原语更适合。

   ```go
   var cs = 0 // 模拟临界区要保护的数据
   var mu sync.Mutex
   var c = make(chan struct{}, 1)
   
   func criticalSectionSyncByMutex() {
       mu.Lock()
       cs++
       mu.Unlock()
   }
   
   func criticalSectionSyncByChan() {
       c <- struct{}{}
       cs++
       <-c
   }
   
   func BenchmarkCriticalSectionSyncByMutex(b *testing.B) {
       for n := 0; n < b.N; n++ {
           criticalSectionSyncByMutex()
       }
   }
   
   func BenchmarkCriticalSectionSyncByChan(b *testing.B) {
       for n := 0; n < b.N; n++ {
           criticalSectionSyncByChan()
       }
   }
   /*
   $go test -bench . go-sync-package-1_test.go 
   goos: darwin
   goarch: amd64
   BenchmarkCriticalSectionSyncByMutex-8           84364287                13.3 ns/op
   BenchmarkCriticalSectionSyncByChan-8            26449521                44.4 ns/op
   PASS
   */
   ```

   sync.Mutex实现的同步机制性能比channel实现的高出两倍多。

2. **不想转移结构体对象所有权，但又要保证结构体内部状态数据的同步访问场景**

   例如要在很多goroutine中访问同一个结构体的内部状态时。

## 35.2 使用sync包的注意事项

在$GOROOT/src/sync/mutex.go文件中，我们看到这样一行关于使用sync包的注意事项：Mutex和RWMutex和Cond在首次使用之后，都不能进行复制使用。如果复制使用，会产生一些非预期错误。

**Mutex的定义**：

1. state：表示当前互斥锁的状态。

2. sema：用于控制锁状态的信号量。

   ```go
   // $GOROOT/src/sync/mutex.go
   type Mutex struct {
      state int32
      sema  uint32
   }
   ```

对锁进行复制时，也会复制锁的当前状态，如果是一个Lock状态的锁，再加锁时会触发死锁。

## 35.3 互斥锁还是读写锁

sync包提供了两种用于临界区同步的原语：互斥锁（Mutex）和读写锁（RWMutex）。互斥锁是临界区同步原语的首选，它常被用来对结构体对象的内部状态、缓存等进行保护，是使用最为广泛的临界区同步原语。相比之下，读写锁颇受“冷落”，但它依然有其存在的道理和适用的场景。

```go
// chapter6/sources/go-sync-package-3_test.go 

var cs1 = 0 // 模拟临界区要保护的数据
var mu1 sync.Mutex
var cs2 = 0 // 模拟临界区要保护的数据
var mu2 sync.RWMutex

func BenchmarkReadSyncByMutex(b *testing.B) {
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            mu1.Lock()
            _ = cs1
            mu1.Unlock()
        }
    })
}

func BenchmarkReadSyncByRWMutex(b *testing.B) {
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            mu2.RLock()
            _ = cs2
            mu2.RUnlock()
        }
    })
}

func BenchmarkWriteSyncByRWMutex(b *testing.B) {
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            mu2.Lock()
            cs2++
            mu2.Unlock()
        }
    })
}
```

对性能进行测试，可以得到如下结果：

1. 在并发量较小的情况下，互斥锁性能更好；
2. 随着并发量增大，互斥锁的竞争激烈，导致加锁和解锁性能下降。
3. 读写锁的读锁性能并未随并发量的增大而发生较大变化，性能始终恒定在40ns左右。
4. 在并发量较大的情况下，读写锁的写锁性能比互斥锁、读写锁的读锁都差，并且随着并发量增大，其写锁性能有继续下降的趋势

读写锁适合应用在具有一定并发量且读多写少的场合。在有大量并发读的情况下，多个goroutine可以同时持有读锁，从而减少在锁竞争中等待的时间；而互斥锁即便是读请求，同一时刻也只能有一个goroutine持有锁，其他goroutine只能阻塞在加锁操作上等待被调度。

## 35.4 条件变量

sync.Cond是传统的条件变量原语概念在Go语言中的实现。一个条件变量可以理解为一个容器，这个容器中存放着一个或一组等待着某个条件成立的goroutine。当条件成立时，这些处于等待状态的goroutine将得到通知并被唤醒以继续后续的工作。这与百米飞人大战赛场上各位运动员等待裁判员的发令枪声十分类似。

使用sync.Mutex实现：

```go
type signal struct{}
var ready bool

func worker(i int) {
    fmt.Printf("worker %d: is working...\n", i)
    time.Sleep(1 * time.Second)
    fmt.Printf("worker %d: works done\n", i)
}

func spawnGroup(f func(i int), num int, mu *sync.Mutex) <-chan signal {
    c := make(chan signal)
    var wg sync.WaitGroup
    
    for i := 0; i < num; i++ {
        wg.Add(1)
        go func(i int) {
            for {
                mu.Lock()
                if !ready {
                    mu.Unlock()
                    time.Sleep(100 * time.Millisecond)
                    continue
                }
                mu.Unlock()
                fmt.Printf("worker %d: start to work...\n", i)
                f(i)
                wg.Done()
                return
            }
        }(i + 1)
    }
    
    go func() {
        wg.Wait()
        c <- signal(struct{}{})
    }()
    return c
}

func main() {
    fmt.Println("start a group of workers...")
    mu := &sync.Mutex{}
    c := spawnGroup(worker, 5, mu)
    
    time.Sleep(5 * time.Second) // 模拟ready前的准备工作
    fmt.Println("the group of workers start to work...")
    
    mu.Lock()
    ready = true
    mu.Unlock()
    
    <-c
    fmt.Println("the group of workers work done!")
}
```

使用sync.Cond：

```go
// chapter6/sources/go-sync-package-5.go   

type signal struct{}
var ready bool

func worker(i int) {
    fmt.Printf("worker %d: is working...\n", i)
    time.Sleep(1 * time.Second)
    fmt.Printf("worker %d: works done\n", i)
}

func spawnGroup(f func(i int), num int, groupSignal *sync.Cond) <-chan signal {
    c := make(chan signal)
    var wg sync.WaitGroup
    
    for i := 0; i < num; i++ {
        wg.Add(1)
        go func(i int) {
            groupSignal.L.Lock()
            for !ready {
                groupSignal.Wait()
            }
            groupSignal.L.Unlock()
            fmt.Printf("worker %d: start to work...\n", i)
            f(i)
            wg.Done()
        }(i + 1)
    }
    
    go func() {
        wg.Wait()
        c <- signal(struct{}{})
    }()
    return c
}

func main() {
    fmt.Println("start a group of workers...")
    groupSignal := sync.NewCond(&sync.Mutex{})
    c := spawnGroup(worker, 5, groupSignal)
    
    time.Sleep(5 * time.Second) // 模拟ready前的准备工作
    fmt.Println("the group of workers start to work...")
    
    groupSignal.L.Lock()
    ready = true
    groupSignal.Broadcast()
    groupSignal.L.Unlock()
    
    <-c
    fmt.Println("the group of workers work done!")
}
```

相比之前的每次循环条件不满足时sleep，改为sync.Cond之后可以使用Wait进行等待，不用一直循环。

## 35.5 使用sync.Once实现单例模式

Go标准库中，sync.Once定义仅执行一次语义，用于初始化和资源清理过程中，以避免重复执行初始化或资源关闭操作。

可以使用sync.Once实现单例模式：

```go
type Foo struct { }

var once sync.Once
var instance *Foo

func GetInstance(id int) *Foo {
    defer func() {
        if e := recover(); e != nil {
            log.Printf("goroutine-%d: caught a panic: %s", id, e)
        }
    }()
    log.Printf("goroutine-%d: enter GetInstance\n", id)
    once.Do(func() {
        instance = &Foo{}
        time.Sleep(3 * time.Second)
        log.Printf("goroutine-%d: the addr of instance is %p\n", id, instance)
        panic("panic in once.Do function")
    })
    return instance
}

func main() {
    var wg sync.WaitGroup
    for i := 0; i < 5; i++ {
        wg.Add(1)
        go func(i int) {
            inst := GetInstance(i)
            log.Printf("goroutine-%d: the addr of instance returned is %p\n", i, inst)
            wg.Done()
        }(i + 1)
    }
    time.Sleep(5 * time.Second)
    inst := GetInstance(0)
    log.Printf("goroutine-0: the addr of instance returned is %p\n", inst)
    
    wg.Wait()
    log.Printf("all goroutines exit\n")
}
```

once.Do会等待f执行完毕后才返回，这期间其他执行once.Do函数的goroutine（如上面运行结果中的goroutine 2~5）将会阻塞等待；Do函数返回后，后续的goroutine再执行Do函数将不再执行f并立即返回（如上面运行结果中的goroutine 0）；即便在函数f中出现panic，sync.Once原语也会认为once.Do执行完毕，后续对once.Do的调用将不再执行f。

## 35.6 使用sync.Pool减轻垃圾回收压力

sync.Pool是一个数据对象缓冲池，具有如下特点：

1. 它是goroutine并发安全的，可以被多个goroutine同时使用；
2. 放入该缓存池中的数据对象的生命是暂时的，随时都可能被垃圾回收掉；
3. 缓存池中的数据对象是可以重复利用的，这样可以在一定程度上降低数据对象重新分配的频度，减轻GC的压力；
4. sync.Pool为每个P（goroutine调度模型中的P）单独建立一个local缓存池，进一步降低高并发下对锁的争抢。

sync.Pool和常规使用new的对比：

```go
var bufPool = sync.Pool{
    New: func() interface{} {
        return new(bytes.Buffer)
    },
}

func writeBufFromPool(data string) {
    b := bufPool.Get().(*bytes.Buffer)
    b.Reset()
    b.WriteString(data)
    bufPool.Put(b)
}

func writeBufFromNew(data string) *bytes.Buffer {
    b := new(bytes.Buffer)
    b.WriteString(data)
    return b
}

func BenchmarkWithoutPool(b *testing.B) {
    b.ReportAllocs()
    for i := 0; i < b.N; i++ {
        writeBufFromNew("hello")
    }
}

func BenchmarkWithPool(b *testing.B) {
    b.ReportAllocs()
    for i := 0; i < b.N; i++ {
        writeBufFromPool("hello")
    }
}
/*
goos: darwin
goarch: amd64
BenchmarkWithoutPool-8          33605625                32.8 ns/op            64 B/op          1 allocs/op
BenchmarkWithPool-8             53222953                22.8 ns/op             0 B/op          0 allocs/op
PASS
*/
```

但是如果buffer是刚被大数据称大的，并且长期用于处理一些小数据时，buffer占用的大内存得不到释放，会给Go程序带来沉重的内存消耗负担。

1. **限制要放回缓存池中的数据对象大小**

   ```go
   // $GOROOT/src/fmt/print.go
   func (p *pp) free() {
       // 要正确使用sync.Pool,要求每个条目具有大致相同的内存成本
       // 若缓存池中存储的类型具有可变大小的缓冲区
       // 对放回缓存池的对象增加一个最大缓冲区的硬限制(不能大于65 536字节)
       //
       // 参见https://golang.org/issue/23199
       if cap(p.buf) > 64<<10 {
           return
       }
   
       p.buf = p.buf[:0]
       p.arg = nil
       p.value = reflect.Value{}
       p.wrappedErr = nil
       ppFree.Put(p)
   }
   ```

2. **建立多级缓存池**

   ```go
   // $GOROOT/src/net/http/h2_bundle.go
   var (   
       http2dataChunkSizeClasses = []int{
           1 << 10,
           2 << 10,
           4 << 10,
           8 << 10,
           16 << 10,
       }
       http2dataChunkPools = [...]sync.Pool{
           {New: func() interface{} { return make([]byte, 1<<10) }},
           {New: func() interface{} { return make([]byte, 2<<10) }},
           {New: func() interface{} { return make([]byte, 4<<10) }},
           {New: func() interface{} { return make([]byte, 8<<10) }},
           {New: func() interface{} { return make([]byte, 16<<10) }},
       }
   )
   
   func http2getDataBufferChunk(size int64) []byte {
       i := 0
       for ; i < len(http2dataChunkSizeClasses)-1; i++ {
           if size <= int64(http2dataChunkSizeClasses[i]) {
               break
           }
       }
       return http2dataChunkPools[i].Get().([]byte)
   }
     
   func http2putDataBufferChunk(p []byte) {
       for i, n := range http2dataChunkSizeClasses {
           if len(p) == n {
               http2dataChunkPools[i].Put(p)
               return
           }
       }
       panic(fmt.Sprintf("unexpected buffer len=%v", len(p)))
   }
   ```

   ## 35.7 总结

   1. sync.Mutex互斥锁，sync.RWMutex读写锁，sync.Once实现单例，sync.Pool缓冲池，sync.Cond条件变量
   2. 锁通常用于高实时，或单写入，多读取场景
   3. channel用于数据通信