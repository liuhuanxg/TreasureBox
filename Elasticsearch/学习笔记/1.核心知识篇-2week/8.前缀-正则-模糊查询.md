## 其他查询

1. ### 前缀搜索prefix

   1. #### 概念

      以xx开头，不计算相关度评分

   2. #### 原理

      1. 前缀匹配的是term，而不是field
      2. 前缀搜索的性能很差
      3. 前缀搜索没有缓存
      4. 前缀搜索时尽可能把前缀长度设置的更长

   3. #### 语法

      ```python
      # 创建索引
      PUT test
      {
        "mappings": {
          "_doc": {
            "_all": {
              "enabled": false
            },
            "properties": {
              "text": {
                "type": "text",
                "analyzer": "ik_max_word",
                "fields": {
                  "keyword": {
                    "type": "keyword",
                    "ignore_above": 256
                  }
                },
                "index_prefixes": {
                  "min_chars": 2,
                  "max_chars": 3
                }
              }
            }
          }
        }
      }
      
      # 先写入数据
      POST _bulk
      {"index":{"_index":"test","_type":"_doc","_id":"1"}}
      {"text":"城管打电话喊商贩去摆地摊"}
      {"index":{"_index":"test","_type":"_doc","_id":"2"}}
      {"text":"笑果文化回应商贩老农去摆地摊"}
      {"index":{"_index":"test","_type":"_doc","_id":"3"}}
      {"text":"老农耗时17年种出椅子树"}
      {"index":{"_index":"test","_type":"_doc","_id":"4"}}
      {"text":"夫妻结婚30多年AA制，被城管抓"}
      {"index":{"_index":"test","_type":"_doc","_id":"5"}}
      {"text":"黑人见义勇为组织抢劫反被铐住"}
      
      GET test/_search
      {
        "query": {
          "prefix": {
            "text": {
              "value": "城管"
            }
          }
        }
      }
      ```

   4. 支持的参数：

      1. `min_chars`：建立前缀索引时开始字符的最小长度，比如设置为2，表示从2个字符开始
      2. `max_chars`：建立前缀索引时开始字符的最大长度，比如设置为5，表示最大5个字符

2. ### 通配符

   1. #### 概念

      1. 通配符运算符是匹配一个或多个字符的占位符。例如，*通配符运算符匹配零个或多个字符。您可以将通配符运算符与其他字符结合使用以创建通配符模式。

   2. #### 用法

      1. 使用通配符查询，关键词：`wildcard`

         ```python
         PUT product_en
         {
           "mappings": {
             "_doc": {
               "_all": {
                 "enabled": false
               },
               "properties": {
                 "desc": {
                   "type": "text",
                   "fields": {
                     "keyword": {
                       "type": "keyword",
                       "ignore_above": 256
                     }
                   }
                 },
                 "title": {
                   "type": "text",
                   "fields": {
                     "keyword": {
                       "type": "keyword",
                       "ignore_above": 256
                     }
                   }
                 },
                 "tags": {
                   "type": "text",
                   "fields": {
                     "keyword": {
                       "type": "keyword",
                       "ignore_above": 256
                     }
                   }
                 }
               }
             }
           }
         }
         
         
         POST /product_en/_bulk
         { "index": { "_id": "1"} }
         { "title": "my english","desc" :  "shouji zhong de zhandouji","price" :  3999, "tags": [ "xingjiabi", "fashao", "buka", "1"]}
         { "index": { "_id": "2"} }
         { "title": "xiaomi nfc phone","desc" :  "zhichi quangongneng nfc,shouji zhong de jianjiji","price" :  4999, "tags": [ "xingjiabi", "fashao", "gongjiaoka" , "asd2fgas"]}
         { "index": { "_id": "3"} }
         { "title": "nfc phone","desc" :  "shouji zhong de hongzhaji","price" :  2999, "tags": [ "xingjiabi", "fashao", "menjinka" , "as345"]}
         { "title": { "_id": "4"} }
         { "text": "xiaomi erji","desc" :  "erji zhong de huangmenji","price" :  999, "tags": [ "low", "bufangshui", "yinzhicha", "4dsg" ]}
         { "index": { "_id": "5"} }
         { "title": "hongmi erji","desc" :  "erji zhong de kendeji","price" :  399, "tags": [ "lowbee", "xuhangduan", "zhiliangx" , "sdg5"]}
         
         GET product_en/_search
         {
           "query": {
             "wildcard": {
               "title": {
                 "value": "eng*ish"
               }
             }
           }
         }
         
         ```

3. ### 正则表达式

   1. #### 关键词：`regex`		

   2. #### 示例：

      ```python
      GET product_en/_search
      {
        "query": {
          "regexp": {
            "desc.keyword": {
              "value": "zh~o",
              "flags": "COMPLEMENT"
            }
          }
        }
      }
      ```

   3. #### flags参数说明：

      1. ALL

         >启用所有可选操作符。

      2. COMPLEMENT

         >启用~操作符。可以使用~对下面最短的模式进行否定。例如
         >
         >a~bc  # matches 'adc' and 'aec' but not 'abc'

      3. INTERVAL

         >启用<>操作符。可以使用<>匹配数值范围。例如
         >
         >foo<1-100>    # matches 'foo1', 'foo2' ... 'foo99', 'foo100'
         >
         >foo<01-100>   # matches 'foo01', 'foo02' ... 'foo99', 'foo100'

      4. INTERSECTION

         >启用&操作符，它充当AND操作符。如果左边和右边的模式都匹配，则匹配成功。例如:
         >
         >aaa.+&.+bbb  # matches 'aaabbb'

      5. ANYSTRING

         >启用@操作符。您可以使用@来匹配任何整个字符串。
         >您可以将@操作符与&和~操作符组合起来，创建一个“everything except”逻辑。例如:
         >
         >@&~(abc.+)  # matches everything except terms beginning with 'abc'

4. ### 模糊查询 -fuzzy

   >混淆字符 (**b**ox → fox)							
   >
   >缺少字符 (**b**lack → lack)
   >
   >多出字符 (sic → sic**k**)							
   >
   >颠倒次序 (a**c**t → **c**at)

   1. #### 示例

      ```python
      
      
      GET <index>/_search
      {
        "query": {
          "fuzzy": {
            "<field>": {
              "value": "<keyword>"
            }
          }
        }
      }
      
      # 模糊匹配
      GET product_en/_search
      {
        "query": {
          "fuzzy": {
            "desc": {
              "value": "zhon"
            }
          }
        }
      }
      
      ```

   2. #### 参数说明

      1. `value`：必须，搜索的字段
      2. `fuzziness`：编辑距离：(0,1,2)并非越大越好，召回率高但结果不准确，例如zho到zhong的编辑距离为2
         1. 最小编辑距离：一个单词经过（插入、删除、修改、调换）转换为另一个单词时需要的次数
         2. `transpositions`：表示编辑距离修改时是否包含反转。默认为true，包含反转，false时不包含反转。如设置为false，fuzziness设置为1时，`hzong`不能匹配到`zhong`。因为`hzong`转换为`zhong`在不反转时需要两次操作。

   3. 在match中使用fuzziness

      ```python
      GET product_en/_search
      {
        "query": {
          "match": {
            "desc": {
              "query": "quangengneng",
              "fuzziness": 1
            }
          }
        }
      }
      ```

5. ### 智能推荐

6. ### match_phrase_prefix

   1. #### match_phrase

      1. match_phrase_prefix会分词
      2. 被检索字段必须包含match_phrase中的所有词频并且顺序必须是相同的
      3. 被检索字段包含的match_phrase中的词项之间不能有其他词项

   2. ##### 概念：

      ​	match_phrase_prefix与match_phrase相同，但是它多了一个特性,就是它允许在文本的最后一个词项(term)上的前缀匹配,如果是一个单词，比如a，它会匹配文档字段所有以a开头的文档，如果是一个短语，比如 "this is ma" ，他会先在倒排索引中做以ma做前缀搜索，然后在匹配到的doc中做match_phrase查询，(网上有的说是先match_phrase，然后再进行前缀搜索,，是不对的)。

      ##### 参数

      - analyzer：指定何种分析器来对该短语进行分词处理
      - max_expansions：在分片级别限制匹配的最大词项，如果多个分片还是会返回多个结果
      - boost：用于设置该查询的权重
      - slop：允许短语间的词项(term)间隔：slop 参数告诉 match_phrase 查询词条相隔多远时仍然能将文档视为匹配。
        - 相隔多远： 意思是说为了让查询和文档匹配你需要移动词条多少次。
        - 例如：slop为1时，使用`shouji de` 可以匹配到`shouji zhong de`

   3. #### 用法

      ```python
      GET product_en/_search
      {
        "query": {
          "match_phrase_prefix": {
            "desc": {
              "query": "shouji zhong de",
              "max_expansions": 1
            }
          }
        }
      }
      
      # 添加上slop参数
      GET product_en/_search
      {
        "query": {
          "match_phrase_prefix": {
            "desc": {
              "query": "shouji de",
              "max_expansions": 1,
              "slop":1
            }
          }
        }
      }
      ```

7. ### N-gram和edge ngram

   1. ##### tokenizer

      ```python
      GET _analyze
      {
        "tokenizer": "ngram",
        "text": "reba always loves me"
      }
      ```

   2. ##### token filter

      ```python
      GET _analyze
      {
        "tokenizer": "ik_max_word",
        "filter": [ "ngram" ],
        "text": "reba always loves me"
      }
      ```

   - ##### min_gram：创建索引所拆分字符的最小阈值

   - ##### max_gram：创建索引所拆分字符的最大阈值

   

   ##### ngram：从每一个字符开始,按照步长,进行分词,适合前缀中缀检索

   ##### edge_ngram：从第一个字符开始,按照步长,进行分词,适合前缀匹配场景

