# ES基本介绍

## 倒排索引

### 从一条数据入门倒排索引

| id    | **title**   | **info**                         |
| ----- | ----------- | -------------------------------- |
| 1     | 念奴娇·昆仑 | 横空出世，莽昆仑，阅尽人间春色…. |
| **2** | 公无渡河    | 黄河西来决昆仑，咆哮万里触龙门…  |

#### 在mysql中查询:

 select * from table where info like “%昆仑%“;这种查询时索引失效

#### 倒排索引数据的存储格式

通过为每一个field分词后建立倒排索引加速查找效率，以field value为key，数据id为值组建结构

| **term** | **posting list** |
| -------- | ---------------- |
| 横空出世 | 1                |
| 莽       | 1                |
| 昆仑     | 1,2              |
| 黄河     | 2                |

## Elastic Stack(ELKB)家族

### Elastic Search

是一个分布式的开放搜索和分析引擎，适用于所有类型的数据格式，包括文本、数字、地理空间、结构化和非结构化数据，基于Lucene基础开发。是一个近实时的搜索平台(1秒)左右。

### LogStash

开放性的服务器端数据处理管道，能够从多个来源采集数据、转换数据，对数据进行聚合和处理，然后将数据发送到存储库中。

### Kibana

搜索、查看并可视化es中存储的数据，并通过创建柱状图、饼状图、表格、直方图、地图等对数据进行分析。

### Beats

轻量级数据采集器，可以从各种环境中收集日志、指标安全数据或网格数据，通过logstash或kafka等传输到es中进行存储。

## 核心概念

### 集群(cluster)

集群由一个或多个节点组成，通过集群名称进行表示。通常集群名称在ES配置文件(config/elasticsearch.tml)中设置



### 节点(node)

单个ES实例成为节点，依据功能可以分为下面几种，在(config/elasticsearch.tml)配置：

**master**：候选节点（创建、更新、删除索引，添加、删除node，分配shard）

**data**：数据节点

data_content：数据内容没电

**data_hot**：热节点，可读可更新

**data_warm**：warm节点：只读不更新

**data_code**：冷节点，存放历史数据（不常访问）

ingest：预处理节点，类似LogStash中的Filter

ml(machine learning)：机器学习节点

**voting node**：仅投票节点（选主）

**coordination node**：协调节点，接受外部请求并转发到相应节点（不特指某个节点，所有节点都有可能成为协调节点）



**如何避免脑裂：**

**脑裂**：正常es集群中只有一个主节点，主节点负责管理整个集群，集群的所有节点都会选择同一个节点作为主节点，所以无论访问那个节点都可以查看集群的状态信息。 而脑裂问题的出现就是因为从节点在选择主节点上出现分歧导致一个集群出现多个主节点从而使集群分裂，使得集群处于异常状态。

**原因**：

1. 网络问题：主节点未及时响应，集群以为主节点下线，选举一个新的主节点，原主节点恢复后集群就会形成两个主节点，导致集群分裂

2. 节点负载：主节点同时承担数据节点角色时，可能会出现负载比较大，引发较大规模的内存回收(GC)，造成ES进程失去响应。

3. 内存回收：数据节点上的ES进程占用的内存较大，较大规模的内存回收操作也能造成ES进程失去响应

**解决办法**：

1. master node与data node分别设置，即node.master与node.data不要同时为True，主节点配置为：node.master: true ，node.data: false。数据节点配置为：node.master: false，node.data: true。

2. 调整节点响应超时时间：discovery.zen.ping_timeout默认为(3s)，如果master节点超过3s未响应时就认为master节点挂了，增加等待响应时间能减少误判。

3. 调整discovery.zen.minimum_master_nodes(默认值是1)参数，该参数表示， 一个节点需要看到的具有master节点资格的最小数量， 然后才能在集群中做操作，即重新选举主节点。官方的推荐值是(N/2)+1，其中 N 是具有 master资格的节点的数量，即只有超过(N/2)+1个主节点同意，才能重新选举主节点。

**从脑裂中恢复**：

1. 给所有数据重新索引：POST _reindex{ "source": { "index": "index_name" }, "dest": { "index": "new_index_name", "op_type": "create" } }

2. 逐个关闭节点并备份数据，分析比对数据是否是最新的。如果是保存的数据是最新的，启动它并且让它被选为主节点，之后启动集群中其他节点。

### 索引(index)

​	类似数据库的概念，以分片为单位，可以设置副本及分片个数

### 类型(type)

每一个index中分为不同的type，使用type可以在同一个index里存储多种类型的数据，可以减少index的数量，好处是搜索同一个index 的多个type时不会产生额外的开销，因为遍历的分片数是一样的。

示例：index为qemu_disk_iostat，type为qemu_disk_iostat_20230312、qemu_disk_iostat_20230313

缺点：不同type名称相同的field要完全保持一致（字段类型、是否能索引等）；在某个type有的字段，其他没有该字段的type也会消耗资源(posting list,doc value)。搜索评分是在index级别计算，多个type会相互影响，**比较鸡肋**。如果只是相对数据进行分割，使用多个index比使用type要好。

在7.x版本中弱化，统一使用_doc使用，在8.x中彻底删除。

### 分片(shard)

一个索引中包含一个或者多个分片，在7.0之前默认创建5个分片，每个主分片一个副本；7.x之后默认创建1个主分片，每个节点默认只允许1000个分片。副本可以在索引创建之后修改数量，但是主分片的数量一旦确定之后不能修改，只能删除之后重新创建。

主分片挂掉之后副分片升级为主分片。原分片加入之后从当前主分片中同步数据。主分片和副分片不会在同一个节点中。

每个分片都是一个**Lucene**实例，有完整的创建索引和处理请求能力，搜索时**所有**的分片都会被扫描，最终被ES合并所有的搜索结果。

**ES会在nodes上做分片均衡**：所有的分片尽量均匀的分布在所有的节点上rebalance(分片平衡策略)。一个doc不会存在于多个主分片中，但是当每个主分片的副本数量不唯一时，可以同时存在于多个副本中

**分片设计原则：**受JVM大小影响，64G内存机器按照每个分片30-50G分配，32G机器按照最大不超过30G分配。分片数尽量保证data node的整数倍。例如3个data node 64G内存节点，索引大小为500GB，则分应设置12个分片，每个42GB左右，3个节点每个可以分4个分片。

### 副本(replace)

副本分片，主分片和副分片不能在同一个节点上，如果设置副本>0时，最少要有两个data node，否则分配一直处于无法分配状态。

### 文档(doc)

es中的数据都是以json文档的形式存储，是数据存储的基本单元，每个doc都会有_id字段，可以在存储时指定_id，或者es会自动生成，推荐自动生成，es默认根据_id做routing，分配该数据要存储的分片。

**routing计算规则：**

shard = hash(routing) % number_of_primary_shards

routing可以自定义，这样方便将某一类数据分配在同一个分片中，但是如果设置的routing不合适，可能导致数据写入不均。

### mapping

maping类似于RDB中的“表结构”概念，在MySQL中，表结构里包含了字段名称，字段的类型还有索引信息等。在Mapping里也包含了一些属性，比如字段名称、类型、字段使用的分词器、是否评分、是否创建索引等属性，并且在ES中一个字段可以有对个类型。分词器、评分等概念。

#### 常见类型

**数字类型：**

long 个带符号的 64 位整数，最小值为，最大值为。 -263 263-1

integer 一个带符号的 32 位整数，最小值为，最大值为。 -231 231-1

short 一个带符号的 16 位整数，最小值为-32768，最大值为32767。

byte 一个带符号的 8 位整数，最小值为-128，最大值为127。

double 双精度 64 位 IEEE 754 浮点数，仅限于有限值。最小2的-1074次方

float 单精度 32 位 IEEE 754 浮点数，仅限于有限值。最小2的-149次方

half_float 半精度 16 位 IEEE 754 浮点数，仅限于有限值。最小2的-24次方

scaled_float 由 支持的有限浮点数long，按固定double比例因子缩放

**keyword** ：适用于索引结构化的字段，可以用于过滤、排序、聚合。keyword类型的字段只能通过精确值（exact value）搜索到。

**Date类型**：包括date和 date_nanos

**text**：全文索引会被用于分词

**对象关系类型**：

object：用于单个JSON对象

nested：用于JSON对象数组

**结构化类型：**

geo-point：纬度/经度积分

geo-shape：用于多边形等复杂形状

point：笛卡尔坐标点

shape：笛卡尔任意几何图形

**特殊类型：**

**ip**：用于IPv4和IPv6地址

…

**array（数组）**

数组不需要专用的字段数据类型。默认情况下，任何字段都可以包含零个或多个值，但是数组中的所有值都必须具有相同的数据类型

#### 动态字段映射(Dynamic field mapping)

建议使用ES时显示指定字段类型，毕竟相对于ES，写入者更了解自己的数据。如果不指定字段类型时ES的默认映射方式：

整数 => long

浮点数 => float

true || false => boolean

日期 => date

数组 => 取决于数组中的第一个有效值

对象 => object

字符串 => 如果不是数字和日期类型，会被映射为text和keyword两个类型

| 基本数据类型 | 占用的内存（byte） | 范围                 |
| ------------ | ------------------ | -------------------- |
| byte         | 1                  | -2^7 ~ 2^7-1         |
| short        | 2                  | -2^15 ~ 2^15-1       |
| int          | 4                  | -2^31 ~ 2^31-1       |
| long         | 8                  | -2^63 ~ 2^63-1       |
| float        | 4                  | -3.4e+38 ~ 3.4e+38   |
| double       | 8                  | -1.7e+308 ~ 1.7e+308 |
| boolean      | 1                  | true/false           |
| char         | 2                  | 0~65535              |

**问题**：0应该选择哪种数据结构存储？[推荐阅读](https://mp.weixin.qq.com/s/eIy1Tv1Teonl2HWtvPVUZg)

[

{"id":1,"disk_uuid":"test-diskuuid","util":0, "svctm": 6,"time":"2023-03-12 14:50:00","set":"test-set"}, 

{"id":2,"disk_uuid":"test-diskuuid","util":94.6, "time":"2023-03-12 14:50:10","set":"test-set"}

]

# 数据存储结构

## ES数据存储结构

ES底层使用 Lucene 存储数据，Lucene 的索引包含以下部分：

**inverted index**：倒排索引。
bkd tree: Block k-d tree，用于在高维空间内做索引，如地理坐标的索引。
**column store**：doc values，列式存储，批量读取连续的数据以提高排序和聚合的效率。
**document store**：Store Fileds，行式存储文档，用于控制 doc 原始数据的存储，其中占比最大的是 source 字段。
**term vectors**：用于存储各个词在文档中出现的位置等信息。

## 常见配置项说明

两组示例数据:

[

{"id":1,"title":"念奴娇·昆仑","info":"横空出世，莽昆仑，阅尽人间春色…."},

{"id":2,"title":"公无渡河","info":"黄河西来决昆仑，咆哮万里触龙门…"}

]

[

{"id":1,"disk_uuid":"test","util":0, "svctm": 6,"time":"2023-03-12 14:50:00","set":"test-set"}},

{"id":2,"disk_uuid":"test","util":94.6, "time":"2023-03-12 14:50:10","set":"test-set"}}

]

| 配置项     | **作用**                           | **注意事项**                                                 | **默认值** | **数据格式**                                                 |
| ---------- | ---------------------------------- | ------------------------------------------------------------ | ---------- | ------------------------------------------------------------ |
| _all       | 提供跨字段全文检索                 | （1）会占用额外空间，把 mapping 中的所有字段通过空格拼接起来做索引，在跨字段全文检索才需要打开；（2）在 v6.0+已被弃用，v7.0会正式移除，可以使用 [copy_to] 来自定义组合字段 | 关闭       | 以title和info字段设置all为例*，*存储结构为："念奴娇·昆仑 横空出世，莽昆仑，阅尽人间春色…."es同样会对all字段做分词 |
| _source    | 存储 post 提交到ES的原始 json 内容 | （1）会占用很多存储空间。数据压缩存储，读取会有额外解压开销。（2）不需要读取原始字段内容可以考虑关闭，但关闭后无法 reindex | **开启**   | {"id":1,"title":"念奴娇·昆仑","info":"横空出世，莽昆仑，阅尽人间春色…."}{"id":2,"title":"公无渡河","info":"黄河西来决昆仑，咆哮万里触龙门…"} |
| store      | 是否单独存储该字段                 | （1）会占用额外存储空间，与_source 独立，同时开启 store 和 source 则会将该字段原始内容保存两份，不同字段单独存储，不同字段的数据在磁盘上不连续，若读取多个字段则需要查询多次，如需读取多个字段，需权衡比较 source 与 store 效率 | 关闭       | 通过黄河搜索info信息时，先找到了posting list为2，接着查询具体的info信息info: 黄河西来决昆仑，咆哮万里触龙门…title: 公无渡河，使用时：stored_fields |
| doc_values | 支持排序、聚合                     | 支持排序、聚合会占用额外存储空间，与 source 独立，同时开启 doc_values 和 _source 则会将该字段原始内容保存两份。doc_values 数据在磁盘上采用**列式**存储，关闭后无法使用排序和聚合 | **开启**   | util [0, 94.6]以disk_uuid字段倒排索引为例：test:[1, 2] ,查询disk_uuid为test的sum util值数据，查询到了1, 2，接着进行聚合 |
| index      | 是否加入倒排索引                   | 关闭后无法对其进行搜索，但字段仍会存储到 _source 和 doc_values，字段可以被排序和聚合 | **开启**   | test: [1,2]                                                  |
| enabled    | 是否对该字段进行处理               | 关闭后，只在 _source中存储，类似 index 与 doc_values 的总开关 | **开启**   |                                                              |

### _all

all 字段的作用是提供跨字段查询的支持，把 mapping 中的所有字段通过空格拼接起来做索引。ES在正常查询的过程中，需要指定在哪一个field里面查询，但是在某种场景下比如搜索一首包含“昆仑”的诗，可能在title字段，或者info字段，查询时需要查title或者info中，查询两次。

如果开启al，会将title 字段和info 字段拼接组成一个虚拟的字段all，值为各个field拼接起来的很长的字符串如（念奴娇·昆仑 横空出世….），实现跨字段检索，用户不需要关心查询的数据具体在哪个字段中。

该字段的内容来源于 source 字段，因此默认情况下，该字段的内容并不会被保存，可以通过设置 store 属性来强制保存 all 字段。开启 all 字段，会带来额外的CPU开销和存储，如果没有使用到，可以关闭 all 字段。

### _source

source 字段用于存储 post 到 ES 的原始 json 文档。为什么要存储原始文档呢？因为 ES 采用倒排索引对文本进行搜索，而倒排索引无法存储原始输入文本。一段文本交给ES后，首先会被分析器(analyzer)打散成单词，为了保证搜索的准确性，在打散的过程中，会去除文本中的标点符号，统一文本的大小写，甚至对于英文等主流语言，会把发生形式变化的单词恢复成原型或词根，然后再根据统一规整之后的单词建立倒排索引，经过如此一番处理，原文已经面目全非。因此需要有一个地方来存储原始的信息，以便在搜到这个文档时能够把原文返回给查询者。

是否一定需要存储原始文档？不一定！如果没有取出整个原始 json 结构体的需求，可以在 mapping 中关闭 source 字段或者只在 source 中存储部分字段（使用store）。 

**关闭source的负面影响**：

（1）**不能获取到原文**，不能使用update、update_by_query api
（2）**无法reindex**：如果存储了 source，当 index 发生损坏，或需要改变 mapping 结构时，由于存在原始数据，ES可以通过原始数据自动重建index，如果不存 source 则无法实现
（3）无法在查询中使用script：因为 script 需要访问 source 中的字段

### store

store 决定一个字段是否要被单独存储。source 里面中已经存储了原始的文档，为什么还需要一个额外的 store 属性呢？原因如下：

（1）如果禁用了 source 保存，可以通过指定 store 属性来单独保存某个或某几个字段，而不是将整个输入文档保存到 source 中。

（2）如果 source 中有长度很长的文本（如一篇文章）和较短的文本（如文章标题），当只需要取出标题时，如果使用 source 字段，ES需要读取整个 source 字段，然后返回其中的 title，由此会引来额外的IO开销，降低效率。此时可以选择将 title 的 store 设置为true，在 source 字段外单独存储一份。读取时不必在读取整 source 字段了。但是需要注意，应该避免使用 store 查询多个字段，因为 store 的存储在磁盘上不连续，ES在读取不同的 store 字段时，每个字段的读取均需要在磁盘上进行查询操作，而使用 source 字段可以一次性连续读取多个字段。

### doc_values

倒排索引可以提供全文检索能力，但是无法提供对排序和数据聚合的支持。doc_values 本质上是一个序列化的列式存储结构，适用于聚合（aggregations）、排序（Sorting）、脚本（scripts access to field）等操作。

默认情况下，ES几乎会为所有类型的字段存储doc_value，但是 text 或 text_annotated 等可分词字段不支持 doc values 。如果不需要对某个字段进行排序或者聚合，则可以关闭该字段的doc_value存储。

### index

控制倒排索引，用于标识指定字段是否需要被索引。默认情况下是开启的，如果关闭了 index，则该字段的内容不会被 analyze 分词，也不会存入倒排索引，即意味着该字段无法被搜索。

### enabled

一个 index 和 doc_value 的总开关，如果 enabled 设置为false，则这个字段将会仅存在于 source 中，其对应的 index 和 doc_value 都不会被创建。这意味着，该字段将不可以被搜索、排序或者聚合，但可以通过 source 获取其原始值。

### term_vector

在对文本进行 analyze 的过程中，可以保留有关分词结果的相关信息，包括单词列表、单词之间的先后顺序、单词在原文中的位置等信息。查询结果返回的高亮信息就可以利用其中的数据来返回。默认情况下，term_vector是关闭的，如有需要（如加速highlight结果）可以开启该字段的存储。

### **doc_values详细说明**

1.doc_values 的作用：

基于 lucene 的 solr 和 es 都是使用倒排索引实现快速检索的，也就是通过建立 "搜索关键词 ==>文档ID列表" 的关系映射实现快速检索，但是倒排索引也是有缺陷的，比如我们需要字段值做一些排序、分组、聚合操作，lucene 内部会遍历提取所有出现在文档集合的排序字段，然后再次构建一个最终的排好序的文档集合list，这个步骤的过程全部维持在内存中操作，而且如果排序数据量巨大的话，非常容易就造成solr内存溢出和性能缓慢。

doc values 就是在构建倒排索引时，会对开启 doc values 的字段额外构建一个有序的 "document文档 ==> field value“ 的列式存储映射，从而实现对指定字段进行排序和聚合时对内存的依赖，提升该过程的性能。默认情况下每个字段的 doc values 都是开启的，当然 doc values 也会耗费一定的磁盘空间。

另外 doc values 保存在操作系统的磁盘中，当 doc values 大于节点的可用内存，ES 可以从操作系统页缓存中加载或弹出，从而避免发生 JVM 内存溢出的异常，docValues 远小于节点的可用内存，操作系统自然将所有Doc Values存于内存中（堆外内存），有助于快速访问。

2.doc_values 与 source 的区别？使用 docvalue_fields 检索指定的字段？

post 提交到 ES 的原始 Json 文档都存储在 source 字段中，默认情况下，每次搜索的命中结果都包含文档 source，即使仅请求少量字段，也必须加载并解析整个 source 对象，而 source 每次使用时都必须加载和解析，所以使用 source 非常慢。为避免该问题，当我们只需要返回相当少的支持 doc_values 的字段时，可以使用 docvalue_fields 参数获取选定字段的值。

doc values 存储与 _source 相同的值，但在磁盘上基于列的结构中进行了优化，以进行排序和汇总。由于每个字段都是单独存储的，因此 Elasticsearch 仅读取请求的字段值，并且可以避免加载整个文档 _source。通过 docvalue_fields 可以从建好的列式存储结果中直接返回字段值，毕竟 source 是从一大片物理磁盘去，理论上从 doc values 处拿这个字段值会比 source 要快一点，页面抖动少一点。

3.doc values 通过牺牲一定的磁盘空间带来的好处主要有两个：

节省内存
提升排序，分组等聚合操作的性能

4.如何在 ES 中使用 doc values？

（1）我们首先关注如何激活 doc values，只要开启 doc values 后，排序，分组，聚合的时候会自动使用 doc values 提速。在 ES 中，doc values 默认是开启的，比较简单暴力，可以酌情关闭一些不需要使用 doc values 的字段，以节省磁盘空间，只需要设置 doc_values 为 false 就可以了。

示例如下："session_id":{"type":"string","index":"not_analyzed","doc_values":false}

（2）使用 docvalue_fields 的检索指定的字段：

```
GET test/_search
{
  "query": {
    "match": {
      "disk_uuid": "test"
    }
  },
  "docvalue_fields": ["util", "svctm"]
}
```

**使用方式**

```json
GET product/_search
{
  "stored_fields": ["name","tags","price"],
  "docvalue_fields": [],
  "_source": []
}
```



## 总结：什么场景可以去掉_source?什么场景可以去掉doc_values?

### 去掉_source

原数据过大、指标类数据

### 去掉doc values

不需要用户聚合、排序

# 数据写入过程

## 关键词

**Document（文档）**: 文档是存储在elasticsearch中的一个JSON文件，相当于关系数据库中表的一行数据。

**Shard（分片）**：索引数据可以拆分为较小的分片，每个分片放到不同的服务器上，提高并发能力。Lucene 中的 Lucene index 相当于 ES 的一个 shard。

**Segments（段）**: 分片由多个segments组成，每个segments都是一个独立的倒排索引，且具有不变性，segment 提供了搜索功能。

**Transaction Log（translog，事务日志）**：ES使用translog来记录index,delete,update,bulk请求，保障数据不丢失，如果Elasticsearch需要恢复数据可以从translog中读取。每个分片对应一个translog文件。

**Commit point（提交点）**：记录着所有已知的segment。

**Lucene index** ：由一堆 Segment 的集合加上一个Commit point组成。



## 写入模型

ES 的任意节点可作为写入请求的协调节点，接收用户请求，协调节点先将写入请求 hash 至分片粒度并先转发对应主分片写入，主分片写入成功再转发至从分片，主从分片均写入完毕经协调节点返回客户端成功。写操作一般会经历三种节点：**协调节点**、**主分片**所在节点、**从分片**所在节点。

如图NODE1可视为协调节点，协调节点接收到请求后，确定写入的文档属于分片0，于是将请求转发到分片0的主分片所在的节点NODE3，

NODE3完成写入后，再将请求转发给分片0所属的从分片所在的节点NODE1和NODE2

待所有从分片写入成功后，NODE3则认为整个写入成功并将结果反馈给协调节点，协调节点再将结果返回客户端。





写⼊时设置副本，有副本的索引创建操作，然后写⼊；如果是写⼊后，再设置副本，则此时采⽤的是复制操作ES为了减少磁盘IO保证读写性能，⼀般是每隔⼀段时间（⽐如5分钟）才会把Lucene的segment写⼊磁盘持久化在每个shard中，写⼊流程分为两部分，先写⼊Lucene，后写⼊Translog



## 写入流程优化

### translog flush间隔调整

这是影响ES写⼊的最⼤因素。translog flush操作是将内存中的数据写⼊磁盘，典型的IO操作。ES默认为了写⼊的可靠性，采⽤的配置

为:index.translog.durability: request

每个写⼊请求都flflush到磁盘，确保写操作是可靠的

如果系统接受⼀定概率的数据丢失，可设置为根据固定周期和固定⼤⼩的flush操作，⽐如

index.translog.durability: async

index.translog.sync_interval: 120s

or

index.translog.flflush_threshold_size: 1024mb

设置translog的flush频率可以控制可靠性，要么是按请求，每次请求都flush；要么是按时间，每隔⼀段时间flush⼀次，⼀般为了性能考虑，会设置为每隔5秒或者1分钟flush⼀次；flush间隔时间越⻓，可靠性就会越低。

### 索引刷新间隔refresh_interval

每次索引的refresh会产⽣⼀个新的Lucene段，增⼤refresh周期，可减少段的创建以及后续的Force Merge操作

### 段合并优化

segment merge操作对系统I/O和内存占⽤都⽐较⾼，需要调整参数，改变⾏为。（这点⽤的少）

### indexing buffer

indexing buffer在为doc建⽴索引时使⽤，当缓冲满时会刷⼊磁盘，⽣成⼀个新的segment，这是除了refresh_interval刷新索引之外，另⼀个⽣成新segment的机会。

indices.memory.index_buffer_size

indices.memory.min_index_buffer_size

indices.memory.max_index_buffer_size

当执⾏⼤量的索引操作时，indices.memory.index_buffer_size的默认设置可能不够，这和可⽤堆内存、单节点上的

shard数量相关，可以考虑适当增⼤该值

### 使⽤bulk请求

批量写效率更⾼，每个请求最好避免超过⼏⼗兆，避免给集群带来压⼒

### bulk线程池和队列

建⽴索引过程属于CPU密集型任务，应该使⽤固定⼤⼩的线程池配置，来不及处理的任务放⼊队列。线程池最⼤线程数量应配置为

CPU核⼼数+1，队列可以适当的增加，但要控制⼤⼩，过⼤的队列会导致较⾼的GC压⼒

### 并发执⾏bulk请求

bulk写请求是个⻓任务，为了给系统增加⾜够的写⼊压⼒，写⼊过程应该多个客户端、多线程地并⾏执⾏，直⾄CPU打满。

### ⾃动⽣成Doc ID

如果写⼊doc时指定了id，则ES会先尝试读取原来doc的版本号以判断是否需要更新，这会涉及⼀次读取磁盘的操作。总结下来两点：

减少磁盘的IO操作

⾃动⽣成的ID具有⼀定的规律，有利于FST的压缩。

Lucene从4.0版本开始⼤量使⽤FST（Finite State Transducer）；具有两个优点：1）空间占⽤⼩。通过对词典中单词前缀和后缀的重复利⽤，压缩了存储空间；2）查询速度快，O(len(str))的查询时间复杂度

### 调整字段Mappings

减少字段数量、对于不需要建⽴索引的字段，不写⼊ES（ES+HBase的组合使⽤）

将不需要建⽴索引的字段index属性设置为not_analyzed或no。对字段不分词，或者不索引，可以减少很多运算操作，降低CPU使⽤

减少字段内容⻓度

使⽤不同的分词器，不同的分词器在索引过程中运算复杂度也有较⼤的差异

### 调整_source字段

_source字段⽤于存储doc原始数据，对于部分不需要存储的字段，可以通过includes、excludes过滤。实际环境，⼀般不做调整

### 禁⽤_all字段

ES 5.x _all默认开启，ES 6.x _all字段默认为不启⽤。_all字段中包含所有字段分词后的关键词，作⽤是可以在搜索的时候不指定特定字段，从所有字段中检索。ES 6.x默认禁⽤_all字段主要有以下⼏点原因：

由于需要从其他的全部字段复制所有字段值，导致_all字段占⽤⾮常⼤的空间

_all字段有⾃⼰的分析器，在进⾏某些查询时，结果不符合预期

由于数据重复引起的额外建⽴索引的开销

想要调试时，其内容不容易检查

有些⽤户甚⾄不知道存在这个字段，导致了查询混乱

可以通过mapping中将enabled设置为false来禁⽤_all字段，禁⽤_all字段可以明显降低对CPU和I/O的压⼒。

### 对Analyzed的字段禁⽤Norms

Norms⽤于在搜索时计算doc的评分，如果不需要评分，则可以将其禁⽤：

"title": {"type": "text", "norms": {"enabled": false}}

### index_options设置

index_options⽤于控制在建⽴倒排索引过程中，哪些内容会被添加到倒排索引中；例如doc数量、词频、positions、offsets等，优化这些设置可以⼀定程度上降低索引过程中的运算任务（较少使用）。

# 数据查询过程

## 查询流程示意图

## 查询模型

## 查询优化

### 为⽂件系统cache预留⾜够的内存

命中cache可以降低对磁盘的直接访问频率，搜索很依赖对系统cache的命中；如果某个请求需要从磁盘读取数据，则⼀定会产⽣相对较⾼的延迟。应该⾄少为系统cache预留⼀半的可⽤物理内存，更⼤的内存有更⾼的cache命中率。

### 使⽤更快的硬件

搜索性能在⼀般情况下更多的是在于IO能⼒，使⽤SSD会⽐旋转类存储介质好的多。如果搜索类型属于计算⽐较多，则可以考虑使⽤更快的CPU。

### ⽂档模型

为了让搜索时的成本更低，⽂档应该合理建模。特别是应该避免join操作，嵌套（nested）会使查询慢⼏倍，⽗⼦（parent-child）关系可能使查询慢数百倍，因此最好通过⾮规范化（denormalizing）⽂档来回答相同的问题，则可以显著提⾼搜索速度。

### 预索引数据

例如根据价格区间进行group，以及计算数量，则可以增加price_range字段

PUT index/type/1

{

 "designation": "spoon",

 "price": 13

}

富化为

PUT index/type/1

{

 "designation": "spoon",

 "price": 13,

 "price_range": "10 - 100"

}

### 优化⽇期搜索

在使⽤⽇期范围检索时，使⽤now的查询通常不能缓存，因为匹配到的范围⼀直在变化。但是从⽤户体验的⻆度来看，切换到⼀个完整的⽇期通常是可以接受的，这样可以更好地利⽤查询缓存。因为使⽤now形成的⽇期是⼀个⾮固定的值，每次查询从当前now往前推算形成的时间间隔都会是⼀个崭新的值，因此⽤不到缓存。